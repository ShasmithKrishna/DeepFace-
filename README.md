# DeepFace Recognition
Name - Akkapally Shasmith Krishna <br>
Roll No- 210050008
<h3> Report </h3>

# ResNet
Introduced a new architecture for convolutional neural networks called Residual Networks (ResNets). The main idea behind ResNets is the use of "residual connections," which are connections between the input and output of a layer that bypass one or more layers. This allows the network to learn residual functions, or the differences between the desired output and the output of the current network. This architecture allows for much deeper networks (up to 152 layers) to be trained without the problem of vanishing gradients.

# FaceNet
Introduced a new method for face recognition using a neural network architecture called FaceNet. The method utilizes a triplet loss function that allows the network to learn a compact Euclidean space where distances directly correspond to a measure of face similarity. This method was able to achieve state-of-the-art performance on a number of face recognition benchmarks at the time of publication.

# InceptionNet
Proposed a new neural network architecture called InceptionNet, which was designed to improve the performance of image classification tasks. The architecture is characterized by the use of multiple parallel convolutional and pooling layers at different scales, which allows the network to learn features at multiple resolutions. This allows the network to perform well even when the input images are of different sizes.

# MobileNet
Proposed a new neural network architecture called MobileNet, which is designed to be efficient in terms of computation and memory usage. The architecture utilizes depth-wise separable convolutions, which reduces the number of parameters and computations required by the network. This allows the network to be run on mobile and embedded devices with limited resources.

# DeepFace
Proposed a new neural network architecture called DeepFace, which was designed to improve the performance of face recognition tasks. The architecture is similar to the architecture of AlexNet, but it uses a more complex pipeline of preprocessing and data augmentation to improve the performance of the network.







